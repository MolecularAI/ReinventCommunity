{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.2`: Model building demo\n",
    "For many applications of `REINVENT`, we already have some prior knowledge on a project that we would like to incorporate. One example of how this can be achieved are *predictive models* trained on a collection of compounds, for example `QSAR` models that relate the structure of a compound to an activity / potency endpoint. In this demo, we will explain how to build `scikit-learn` models that are compatible with `REINVENT`. Note, that our model will have the ending `.pkl`, as we need to save the model's parameters in a serialized fashion (\"[pickled](https://docs.python.org/3/library/pickle.html)\").\n",
    "\n",
    "Our input dataset will be `DRD2` (see also the \"complete use-case notebook\"), for which we have compiled two `CSV` files with the compounds' `SMILES` in one column and a read-out value in another (see below). We will train a `Random Forest` regressor here, but you can choose any backend algorithm that provides a `scikit-learn` interface. As of now, `REINVENT` supports 4 different kinds of molecular fingerprints and we will need to calculate them before we can train our model.\n",
    "\n",
    "The following imports are required to execute the code. Please update the output directory path if you want to store the temporary files and the final model in another place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, MACCSkeys, PandasTools\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set plotting parameters\n",
    "large = 22; med = 16; small = 12\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- change these path variables as required\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_model_building_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# copy data sets to temporary folder for inspection\n",
    "copyfile(os.path.join(ipynb_path, \"data/drd2.train.csv\"),\n",
    "         os.path.join(output_dir, \"drd2.train.csv\"))\n",
    "copyfile(os.path.join(ipynb_path, \"data/drd2.test.csv\"),\n",
    "         os.path.join(output_dir, \"drd2.test.csv\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Before proceeding, let us inspect the datasets. We have split them into a training and test sets, each of which has `canonical` (the `SMILES`) and `activity` (either `1` or `0`, corresponding to `active` and `inactive` respectively) columns. This means, we have a (binary) classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# obs in train:  275768\n",
      "# obs in test:  68944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc(NC(=O)CC2C(=O)N(c3ccc(Cl)cc3)C(=S)N2CC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(CSc1oc(-c2ccccc2)nc1S(=O)(=O)c1ccc(Br)cc1)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cn1c(=S)n(CCC(=O)O)c2ccccc21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clc1ccc(NN=Cc2ccncc2)cc1Cl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(C=NO)NCCCNCc1ccccc1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           canonical  activity\n",
       "0  COc1ccc(NC(=O)CC2C(=O)N(c3ccc(Cl)cc3)C(=S)N2CC...         0\n",
       "1  O=C(CSc1oc(-c2ccccc2)nc1S(=O)(=O)c1ccc(Br)cc1)...         0\n",
       "2                       Cn1c(=S)n(CCC(=O)O)c2ccccc21         0\n",
       "3                         Clc1ccc(NN=Cc2ccncc2)cc1Cl         0\n",
       "4                            O=C(C=NO)NCCCNCc1ccccc1         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(output_dir, \"drd2.train.csv\"))\n",
    "test = pd.read_csv(os.path.join(output_dir, \"drd2.test.csv\"))\n",
    "\n",
    "\n",
    "print(\"# obs in train: \", train.shape[0])\n",
    "print(\"# obs in test: \", test.shape[0])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptors\n",
    "As mentioned above, we need to calculate descriptors (fingerprints) which are understood by `REINVENT`. Below is some code to facilitate this for one example configuration (`ECFP6` with counts), but feel free to adapt it if you feel your model could benefit from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_mols(query_smiles):\n",
    "    mols = [Chem.MolFromSmiles(smile) for smile in query_smiles]\n",
    "    valid = [0 if mol is None else 1 for mol in mols]\n",
    "    valid_idxs = [idx for idx, boolean in enumerate(valid) if boolean == 1]\n",
    "    valid_mols = [mols[idx] for idx in valid_idxs]\n",
    "    return valid_mols, valid_idxs\n",
    "\n",
    "\n",
    "class Descriptors:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self._data = data\n",
    "\n",
    "    def ECFP(self, radius, nBits):\n",
    "        fingerprints = []\n",
    "        mols, idx = smiles_to_mols(self._data)\n",
    "        fp_bits = [AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits) for mol in mols]\n",
    "        for fp in fp_bits:\n",
    "            fp_np = np.zeros((1, nBits), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, fp_np)\n",
    "            fingerprints.append(fp_np)\n",
    "        return fingerprints, idx\n",
    "\n",
    "    def ECFP_counts(self, radius, useFeatures, useCounts=True):\n",
    "        mols, valid_idx = smiles_to_mols(self._data)\n",
    "        fps = [AllChem.GetMorganFingerprint(mol, radius, useCounts=useCounts, useFeatures=useFeatures) for mol in mols]\n",
    "        size = 2048\n",
    "        nfp = np.zeros((len(fps), size), np.int32)\n",
    "        for i, fp in enumerate(fps):\n",
    "            for idx, v in fp.GetNonzeroElements().items():\n",
    "                nidx = idx % size\n",
    "                nfp[i, nidx] += int(v)\n",
    "        return nfp, valid_idx\n",
    "\n",
    "    def Avalon(self, nBits):\n",
    "        mols, valid_idx = smiles_to_mols(self._data)\n",
    "        fingerprints = []\n",
    "        fps = [pyAvalonTools.GetAvalonFP(mol, nBits=nBits) for mol in mols]\n",
    "        for fp in fps:\n",
    "            fp_np = np.zeros((1, nBits), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, fp_np)\n",
    "            fingerprints.append(fp_np)\n",
    "        return fingerprints, valid_idx\n",
    "\n",
    "    def MACCS_keys(self):\n",
    "        mols, valid_idx = smiles_to_mols(self._data)\n",
    "        fingerprints = []\n",
    "        fps = [MACCSkeys.GenMACCSKeys(mol) for mol in mols]\n",
    "        for fp in fps:\n",
    "            fp_np = np.zeros((1, ), dtype=np.int32)\n",
    "            DataStructs.ConvertToNumpyArray(fp, fp_np)\n",
    "            fingerprints.append(fp_np)\n",
    "        return fingerprints, valid_idx\n",
    "\n",
    "def get_ECFP6_counts(inp):\n",
    "    if not isinstance(inp, list):\n",
    "        inp = list(inp)\n",
    "    desc = Descriptors(inp)\n",
    "    fps, _ = desc.ECFP_counts(radius=3, useFeatures=True, useCounts=True)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  1  4 ...  0  0  0]\n",
      " [ 9  1  4 ...  0  0  0]\n",
      " [ 3  1  2 ...  0  0  0]\n",
      " ...\n",
      " [11  0  1 ...  1  0  0]\n",
      " [11  1  1 ...  0  0  0]\n",
      " [ 6  0  2 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "train_fps = get_ECFP6_counts(train[\"canonical\"])\n",
    "test_fps = get_ECFP6_counts(test[\"canonical\"])\n",
    "\n",
    "print(train_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "To train your model (i.e. fit the model's parameters to the training data), execute the following cell. Note, that `REINVENT` will access the `proba` property of the model to get a probability rather than a predicted label. If you want to optimize the hyper-parameters of you model, we suggest you use a cross-validation approach (we aim to publish our in-house method based on [optuna](https://optuna.org) soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987600796694758\n"
     ]
    }
   ],
   "source": [
    "# initialize a \"Random Forest Classifier\" (choice of hyper-parameters somewhat arbitrary)\n",
    "RFclassifier = sklearn.ensemble.RandomForestClassifier(max_depth=20,\n",
    "                                                       max_features=\"auto\",\n",
    "                                                       n_estimators=100,\n",
    "                                                       class_weight=\"balanced\")\n",
    "\n",
    "# fit to training data\n",
    "RFclassifier.fit(train_fps, train[\"activity\"])\n",
    "y_pred = RFclassifier.predict(X=train_fps)\n",
    "train_score = roc_auc_score(y_true=train[\"activity\"], y_score=y_pred)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance on test set\n",
    "To get a better idea on how well (or meager) our model performs, we can evaluate it on the test (hold-out) set. These observations have not been used for fitting the parameters and are thus a good proxy for how the model would fare for new compounds generated, e.g. by `REINVENT`. Note, that we do not strive to give a comprehensive tutorial how to build good, well generalizing models in this demonstration and there are quite a few important considerations to contemplate before actually using a model in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961789032126087\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = RFclassifier.predict(X=test_fps)\n",
    "test_score = roc_auc_score(y_true=test[\"activity\"], y_score=y_pred_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out final model\n",
    "Finally, we will write-out the model. Usually, we will build it using all the observations available. While this maximizes the amount of knowledge available to the model, it is noteworthy that this comes at the trade-off of not being able to independently assess the model's performance anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824336871329722\n"
     ]
    }
   ],
   "source": [
    "RFclassifier_final = sklearn.ensemble.RandomForestClassifier(max_depth=20,\n",
    "                                                             max_features=\"auto\",\n",
    "                                                             n_estimators=100,\n",
    "                                                             class_weight=\"balanced\")\n",
    "\n",
    "# fit to all data points\n",
    "complete_fps = np.concatenate((train_fps, test_fps), axis=0)\n",
    "complete_y = pd.concat((train[\"activity\"], test[\"activity\"]))\n",
    "RFclassifier_final.fit(complete_fps, complete_y)\n",
    "y_pred_final = RFclassifier.predict(X=complete_fps)\n",
    "train_score = roc_auc_score(y_true=complete_y, y_score=y_pred_final)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open(os.path.join(output_dir, \"DRD2_final_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(RFclassifier_final, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration into `REINVENT`\n",
    "In order to use your new model as a component in the scoring function of `REINVENT`, you need to include a block with the appropriate parameter settings (see below). Note, that the descriptor definition needs to match.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"component_type\": \"predictive_property\",\n",
    "  \"name\": \"DRD2_pred_activity\",\n",
    "  \"weight\": 1,\n",
    "  \"specific_parameters\": {\n",
    "    \"model_path\": \"/path/to/model/folder/DRD2_final_model.pkl\",\n",
    "    \"scikit\": \"classification\",\n",
    "    \"transformation: {\n",
    "        \"transformation_type\": \"no_transformation\"\n",
    "    },\n",
    "    \"descriptor_type\": \"ecfp_counts\",\n",
    "    \"size\": 2048,\n",
    "    \"radius\": 3,\n",
    "    \"use_counts\": True,\n",
    "    \"use_features\": True\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
