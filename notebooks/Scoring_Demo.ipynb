{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.2`: scoring mode demo\n",
    "One of the more common running modes of `REINVENT 3.2` in a project setting is the *scoring mode*. As is described in detail in the *reinforcement learning* notebooks, an agent can learn (iteratively) to maximise the reward given by a scoring function. Recall that this function can be a (complex) combination of scoring components and it is not always straightforward to predict how a given compound will score. A common use case is to have a couple of compounds at the beginning of the project that are considered \"good\" and one would like to ensure that they score highly. If not, there is still the possibility to change the scoring function accordingly.\n",
    "\n",
    "For this scenario, one can subject a file with molecules in the `SMILES` format to a scoring run, which is illustrated by this notebook.\n",
    "\n",
    "To proceed, please update the following code block such that it reflects your system's installation and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"~/Desktop/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"~/miniconda3/envs/reinvent.v3.2\")\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_scoring_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the configuration\n",
    "`REINVENT` has an entry point that loads a specified `JSON` file on startup. `JSON` is a low-level data format that allows to specify a fairly large number of parameters in a cascading fashion very quickly. The parameters are structured into *blocks* which can in turn contain blocks or simple values, such as *True* or *False*, strings and numbers. In this tutorial, we will go through the different blocks step-by-step, explaining their purpose and potential values for given parameters. Note, that while we will write out the configuration as a `JSON` file in the end, in `python` we handle the same information as a simple `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"scoring\",                 # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"reinforcement_learning\" and\n",
    "                                           #                  \"create_model\"\n",
    "    \"model_type\": \"default\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://127.0.0.1\",          # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # where the run's output is stored\n",
    "    \"job_name\": \"Scoring mode demo\",       # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                       # only relevant if \"recipient\" is set to \"remote\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the *reinforcement learning* notebooks, we do not need to specify any prior or agent files, as we are only interested in the scores and no training is preformed at all. For each of our input molecules (see print-out below), we will calculate all individual components and the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\r\n"
     ]
    }
   ],
   "source": [
    "# set path to dummy input file\n",
    "input_SMILES_path = os.path.join(ipynb_path, \"data\", \"smiles.smi\")\n",
    "\n",
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}\n",
    "\n",
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"scoring\"] = {\n",
    "    \"input\": input_SMILES_path\n",
    "}\n",
    "\n",
    "# print file contents for illustrative purposes\n",
    "!head -n 15 {input_SMILES_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the scoring function\n",
    "Now all that remains to be done is the most tricky step: define a scoring function that allows to identify promising suggestions and discard molecules that are of no interest to the project. It is not necessarily better to build a very complex scoring function (on the contrary it can make it hard for the agent to find appropriate solutions). Always bear in mind that there is a post-processing step at the end, in which you will be able to discard molecules either by eye-inspection or by applying further (probably more expensive) methods you have not used in the reinforcement learning loop. The following example will include fair share of the available scoring function components (added one-by-one), but this is for illustrative purposes only.\n",
    "\n",
    "##### Score transformation\n",
    "Before we start, there is one more topic requiring some explanation: *score transformations*. Remember that every component returns a value between '0' and '1' (higher values meaning \"better\") and all scores together are combined into a *total score* for a given compound (also between '0' and '1'). This is key, as the agent will try to generate molecules with ever increasing scores over the course of training, i.e. the numerical value \"guides\" the agent. However, some components might not naturally return values between '0' or '1' or they might represent the opposite, i.e. '0' being \"good\" rather than \"bad\". This is component-specific and to make it as flexible as possible, we include the specification of a score transformation for each component. We support multiple different functions (`sigmoid`, `reverse_sigmoid` and so on) which have different parameters to allow tweaking them to the desired result. For more details and to see how different parameter values affect the result, we refer to the dedicated notebook which is also part of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_product\",              # this is our default one (alternative: \"custom_sum\")\n",
    "\n",
    "    # the \"parameters\" list holds the individual components\n",
    "    \"parameters\": [\n",
    "\n",
    "    # add component: an activity model\n",
    "    {\n",
    "        \"component_type\": \"predictive_property\", # this is a scikit-learn model, returning\n",
    "                                                 # activity values\n",
    "        \"name\": \"Regression model\",        # arbitrary name for the component\n",
    "        \"weight\": 2,                       # the weight (\"importance\") of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"model_path\": os.path.join(ipynb_path, \"models/Aurora_model.pkl\"),   # absolute model path\n",
    "            \"transformation\": {\n",
    "                \"transformation_type\": \"sigmoid\",  # see description above\n",
    "                \"high\": 9,                         # parameter for sigmoid transformation\n",
    "                \"low\": 4,                          # parameter for sigmoid transformation\n",
    "                \"k\": 0.25,                         # parameter for sigmoid transformation\n",
    "            },\n",
    "            \"scikit\": \"regression\",                # model can be \"regression\" or \"classification\"\n",
    "            \"descriptor_type\": \"ecfp_counts\",      # sets the input descriptor for this model\n",
    "            \"size\": 2048,                          # parameter of descriptor type\n",
    "            \"radius\": 3,                           # parameter of descriptor type\n",
    "            \"use_counts\": True,                    # parameter of descriptor type\n",
    "            \"use_features\": True                   # parameter of descriptor type\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: enforce the match to a given substructure\n",
    "    {\n",
    "        \"component_type\": \"matching_substructure\", \n",
    "        \"name\": \"Matching substructure\",       # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [\"c1ccccc1CC\"],          # a match with this substructure is required\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: enforce to NOT match a given substructure\n",
    "    {\n",
    "        \"component_type\": \"custom_alerts\",\n",
    "        \"name\": \"Custom alerts\",               # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [                            # specify the substructures (as list) to penalize\n",
    "                \"[*;r8]\",\n",
    "                \"[*;r9]\",\n",
    "                \"[*;r10]\",\n",
    "                \"[*;r11]\",\n",
    "                \"[*;r12]\",\n",
    "                \"[*;r13]\",\n",
    "                \"[*;r14]\",\n",
    "                \"[*;r15]\",\n",
    "                \"[*;r16]\",\n",
    "                \"[*;r17]\",\n",
    "                \"[#8][#8]\",\n",
    "                \"[#6;+]\",\n",
    "                \"[#16][#16]\",\n",
    "                \"[#7;!n][S;!$(S(=O)=O)]\",\n",
    "                \"[#7;!n][#7;!n]\",\n",
    "                \"C#C\",\n",
    "                \"C(=[O,S])[O,S]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#7;!n]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#16;!s][C;!$(C(=[O,N])[N,O])][#16;!s]\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: calculate the QED drug-likeness score (using RDkit)\n",
    "    {\n",
    "        \"component_type\": \"qed_score\",\n",
    "        \"name\": \"QED Score\",                   # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": None            # not required; note, this is \"null\" in JSON\n",
    "    }]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that this definition is exactly the same as we have used for the *reinforcement learning* demo. Actually, the differences in the `JSON`s are only marginal: **(a)** replace the `run_type`, **(b)** remove the `results` path and `logging_frequency` in the header (as we will not *generate* any molecules) and **(c)** update the block with the path to the input `SMILES` file.\n",
    "\n",
    "We now have successfully filled the dictionary and will write it out as a `JSON` file in the output directory. Please have a look at the file before proceeding in order to see how the paths have been inserted where required and the `dict` -> `JSON` translations (e.g. `True` to `true`) have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"scoring_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. As we will not update any weights, execution should be very fast. The result will be a `CSV` file in the logging directory, showing the `SMILES` and the individual components for each of them.\n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, the `CSV` always at least three columns: `smiles`, `total_score` and (at the very end) `valid`, providing the molecules in `SMILES` format, the combined score and a flat indicating, whether or not these molecules are valid in the sense that you can build an `RDkit` molecule object from it or not. In between, all the the scoring components we have specified are given with the names we have used in our `JSON`: `Regression model`, `Matching substructure`, `Custom alerts` and `QED Score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles,total_score,Regression model,Matching substructure,Custom alerts,QED Score,raw_Regression model,valid\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n",
      "O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N,0.2070103883743286,0.3067730665206909,0.5,1.0,0.7541053295135498,5.79188346862793,1\r\n"
     ]
    }
   ],
   "source": [
    "# print the resulting CSV file\n",
    "!head -n 15 {output_dir}/progress.log/scored_smiles.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
