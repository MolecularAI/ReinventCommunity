{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.0`: reinforcement learning with DockStream (docking)\n",
    "\n",
    "\n",
    "This is a simple example of running `Reinvent` with only 1 score component (`DockStream`). To execute this notebook, make sure you have cloned the `DockStream` repository from GitHub and installed the conda environment.\n",
    "\n",
    "**NOTE: There is a detailed reasoning for each `REINVENT` code block provided in the `Reinforcement Learning Demo` notebook.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the paths\n",
    "_Please update the following code block such that it reflects your system's installation and execute it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"~/Desktop/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"~/miniconda3/envs/reinvent.v3.0\")\n",
    "\n",
    "# DockStream variables\n",
    "dockstream_dir = os.path.expanduser(\"~/Desktop/ProjectData/DockStream\")\n",
    "dockstream_env = os.path.expanduser(\"~/miniconda3/envs/DockStream/bin/python\")\n",
    "# generate the path to the DockStream entry points\n",
    "docker_path = os.path.join(dockstream_dir, \"docker.py\")\n",
    "\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_RL_DockStream_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate the folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Glide docking variables\n",
    "grid_file_path = os.path.expanduser(\"~/Desktop/ReinventCommunity/notebooks/data/DockStream/1UYD_grid.zip\")\n",
    "output_ligands_docked_poses_path = os.path.expanduser(\"~/Desktop/REINVENT_RL_DockStream_demo/docked_poses\")\n",
    "output_ligands_docking_scores_path = os.path.expanduser(\"~/Desktop/REINVENT_RL_DockStream_demo/docking_scores\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_ligands_docked_poses_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_ligands_docking_scores_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "docking_configuration_path = os.path.join(output_dir, \"Glide_DockStream_Conf.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the `DockStream` Configuration\n",
    "_Please update the following code block such that it reflects your system's installation and execute it._\n",
    "\n",
    "In this notebook, we will demonstrate how to use `DockStream` with `REINVENT`. `Glide` with `LigPrep` will be used as the molecular docking component. For more details regarding using `Glide` in `DockStream`, see the `demo_Glide` notebook in the `DockStreamCommunity` repository. There, all details and supported functionalities are presented. The `Glide` with `LigPrep` configuration used in this notebook is the simplest case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the embedding and docking JSON file as a dictionary and write it out\n",
    "ed_dict = {\n",
    "  \"docking\": {\n",
    "    \"header\": {                                   # general settings\n",
    "      \"environment\": {\n",
    "      }\n",
    "    },\n",
    "    \"ligand_preparation\": {                       # the ligand preparation part, defines how to build the pool\n",
    "      \"embedding_pools\": [\n",
    "        {\n",
    "          \"pool_id\": \"Ligprep_pool\",\n",
    "          \"type\": \"Ligprep\",\n",
    "          \"parameters\": {\n",
    "            \"prefix_execution\": \"module load schrodinger/2019-4\",\n",
    "            \"parallelization\": {\n",
    "                \"number_cores\": 2\n",
    "            },\n",
    "            \"use_epik\": {\n",
    "              \"target_pH\": 7.0,\n",
    "              \"pH_tolerance\": 2.0\n",
    "            },\n",
    "            \"force_field\": \"OPLS3e\"\n",
    "          },\n",
    "          \"input\": {\n",
    "            \"standardize_smiles\": False,\n",
    "            \"type\": \"console\"                     # input type \"console\" when using DockStream with REINVENT\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"docking_runs\": [\n",
    "        {\n",
    "          \"backend\": \"Glide\",\n",
    "          \"run_id\": \"Glide_run\",\n",
    "           \"input_pools\": [\"Ligprep_pool\"],\n",
    "          \"parameters\": {\n",
    "              \"prefix_execution\": \"module load schrodinger/2019-4\", # will be executed before a program call\n",
    "              \"parallelization\": {                                  # if present, the number of cores to be used\n",
    "                                                                    # can be specified\n",
    "            \"number_cores\": 2\n",
    "          },\n",
    "          \"glide_flags\": {                                  # all all command-line flags for Glide here \n",
    "            \"-HOST\": \"localhost\"\n",
    "          },\n",
    "          \"glide_keywords\": {                               # add all keywords for the \"input.in\" file here\n",
    "                                                            # this is the minimum keywords that needs to be \n",
    "                                                            # specified and represents a simple `Glide` \n",
    "                                                            # docking configuration\n",
    "                                                            \n",
    "            \"GRIDFILE\": grid_file_path,\n",
    "            \"POSE_OUTTYPE\": \"ligandlib_sd\",\n",
    "            \"PRECISION\": \"HTVS\"\n",
    "          }\n",
    "        },\n",
    "        \"output\": {\n",
    "          \"poses\": { \"poses_path\": os.path.join(output_ligands_docked_poses_path, \"docked_poses.sdf\")},\n",
    "          \"scores\": { \"scores_path\": os.path.join(output_ligands_docking_scores_path, \"docking_scores.csv\")}\n",
    "        }\n",
    "      }]}}\n",
    "\n",
    "with open(docking_configuration_path, 'w') as f:\n",
    "    json.dump(ed_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set up the `REINVENT` configuration \n",
    "In the cells below we will build a nested dictionary object that will be eventually converted to JSON file which in turn will be consumed by `REINVENT`. \n",
    "You can find this file in your `output_dir` location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Declare the run type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"reinforcement_learning\"   # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"scoring\" and \"create_model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Sort out the logging details\n",
    "This includes `result_folder` path where the results will be produced.\n",
    "\n",
    "Also: `REINVENT` can send custom log messages to a remote location. We have retained this capability in the code. if the `recipient` value differs from `\"local\"` `REINVENT` will attempt to POST the data to the specified `recipient`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://0.0.0.1\",            # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_frequency\": 1,                # log every x-th steps\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # load this folder in tensorboard\n",
    "    \"result_folder\": os.path.join(output_dir, \"results\"),         # will hold the compounds (SMILES) and summaries\n",
    "    \"job_name\": \"Reinforcement learning DockStream demo\",         # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                       # only relevant if \"recipient\" is set to a specific REST endpoint\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `parameters` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Set Diversity Filter\n",
    "During each step of Reinforcement Learning the compounds scored above `minscore` threshold are kept in memory. Those scored smiles are written out to a file in the results folder `scaffold_memory.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"diversity_filter\"\n",
    "configuration[\"parameters\"][\"diversity_filter\"] =  {\n",
    "    \"name\": \"IdenticalMurckoScaffold\",     # other options are: \"IdenticalTopologicalScaffold\", \n",
    "                                           #                    \"NoFilter\" and \"ScaffoldSimilarity\"\n",
    "                                           # -> use \"NoFilter\" to disable this feature\n",
    "    \"nbmax\": 25,                           # the bin size; penalization will start once this is exceeded\n",
    "    \"minscore\": 0.4,                       # the minimum total score to be considered for binning\n",
    "    \"minsimilarity\": 0.4                   # the minimum similarity to be placed into the same bin\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Set Inception\n",
    "* `smiles` provide here a list of smiles to be incepted \n",
    "* `memory_size` the number of smiles allowed in the inception memory\n",
    "* `sample_size` the number of smiles that can be sampled at each reinforcement learning step from inception memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the inception (we do not use it in this example, so \"smiles\" is an empty list)\n",
    "configuration[\"parameters\"][\"inception\"] = {\n",
    "    \"smiles\": [],                          # fill in a list of SMILES here that can be used (or leave empty)\n",
    "    \"memory_size\": 100,                    # sets how many molecules are to be remembered\n",
    "    \"sample_size\": 10                      # how many are to be sampled each epoch from the memory\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Set the general Reinforcement Learning parameters\n",
    "* `n_steps` is the amount of Reinforcement Learning steps to perform. Best start with 1000 steps and see if thats enough.\n",
    "* `agent` is the generative model that undergoes transformation during the Reinforcement Learning run.\n",
    "\n",
    "We reccomend keeping the other parameters to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"reinforcement_learning\"] = {\n",
    "    \"prior\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"agent\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"n_steps\": 2,                          # the number of epochs (steps) to be performed; often 1000\n",
    "                                           # (set to 2 in this notebook to decrease docking computation time -\n",
    "                                           # it is not expected that the agent will appreciably learn to\n",
    "                                           # generate compounds with good docking scores in only 2 epochs.\n",
    "                                           # The purpose of this notebook is to illustrate how DockStream \n",
    "                                           # can be specified as a component to the `Scoring Function`)\n",
    "    \n",
    "    \"sigma\": 128,                          # used to calculate the \"augmented likelihood\", see publication\n",
    "    \"learning_rate\": 0.0001,               # sets how strongly the agent is influenced by each epoch\n",
    "    \"batch_size\": 32,                      # specifies how many molecules are generated per epoch, often 128\n",
    "                                           # docking becomes more computationally demanding the greater the\n",
    "                                           # batch size, as each compound must be docked. Depending on the\n",
    "                                           # docking configuration, embedding ligands may generate different \n",
    "                                           # tautomers, ionization states, etc., which will increase the number\n",
    "                                           # of compounds that need to be docked. Batch size is set to 32 in \n",
    "                                           # this notebook to decrease docking computation time)\n",
    "    \n",
    "    \"reset\": 0,                            # if not '0', the reset the agent if threshold reached to get\n",
    "                                           # more diverse solutions\n",
    "    \"reset_score_cutoff\": 0.5,             # if resetting is enabled, this is the threshold\n",
    "    \"margin_threshold\": 50                 # specify the (positive) margin between agent and prior\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Define the scoring function\n",
    "The scoring function will consist only of the `DockStream` component, in which `Glide` with `LigPrep` is used for molecular docking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_product\",                  # this is our default one (alternative: \"custom_sum\")\n",
    "    \"parallel\": False,                         # sets whether components are to be executed\n",
    "                                               # in parallel; note, that python uses \"False\" / \"True\"\n",
    "                                               # but the JSON \"false\" / \"true\"\n",
    "\n",
    "    # the \"parameters\" list holds the individual components\n",
    "    \"parameters\": [\n",
    "\n",
    "    # add component: use \n",
    "    {\n",
    "    \"component_type\": \"dockstream\",                           # use DockStream as a Scoring Function component      \n",
    "    \"name\": \"Glide LigPrep Docking\",                          # arbitrary name\n",
    "    \"weight\": 1,\n",
    "    \"specific_parameters\": {\n",
    "        \"transformation\": {\n",
    "            \"transformation_type\": \"reverse_sigmoid\",         # lower Glide scores are better - use reverse\n",
    "                                                              # sigmoid transformation\n",
    "            \"low\": -11,\n",
    "            \"high\": -5,\n",
    "            \"k\": 0.25\n",
    "            },\n",
    "        \"configuration_path\": docking_configuration_path,\n",
    "        \"docker_script_path\": docker_path,\n",
    "        \"environment_path\": dockstream_env\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write out the `REINVENT` configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully filled the dictionary and will write it out as a `JSON` file in the output directory. Please have a look at the file before proceeding in order to see how the paths have been inserted where required and the `dict` -> `JSON` translations (e.g. `True` to `true`) have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"RL_DockStream_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. Note, that depending on the number of epochs (steps) and the execution time of the scoring function components, this might take a while. As we have only specified a low number of epochs (125) and all components should be fairly quick, this should not take too long in our case though.\n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.0\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)\n",
    "\n",
    "# prepare the output to be parsed\n",
    "list_epochs = re.findall(r'INFO.*?local', captured_err_stream.stdout, re.DOTALL)\n",
    "data = [epoch for idx, epoch in enumerate(list_epochs)]\n",
    "data = [\"\\n\".join(element.splitlines()[:-1]) for element in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated a total of 2 epochs, let us quickly investigate how the agent fared in the first epoch. Below you see the print-out of the first epoch. Running `REINVENT` with `DockStream` for more epochs will show that the agent gradually improves over time, i.e, generates compounds that satisfy the docking component, thus generating compounds that dock well. Note, that the fraction of valid `SMILES` is high right from the start (because we use a pre-trained prior). You can see the partial scores for each component for the first couple of compounds, but the most important information is the average score. If run for more epochs, the average score will increase over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     starting an RL run\n",
      "INFO     \n",
      " Step 0   Fraction valid SMILES: 100.0   Score: 0.1702   Time elapsed: 229   Time left: 458.0\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-27.59    -27.59      2.99      0.24      C1(O)(c2cccc(Cl)c2)CC2N(Cc3c(C)noc3C)C(CC2)C1\n",
      "-23.84    -23.84      3.04      0.21      C1(C)N(S(c2cccc(Cl)c2C)(=O)=O)CCNC1=O\n",
      "-24.26    -24.26    -21.44      0.02      c1(C2C(C(OCC)=O)=C(C)N=C3CC(c4cc(OC)c(OC)cc4)CC(=O)C23)cscc1\n",
      "-37.08    -37.08    -30.63      0.05      C1CN(CCCN(C2CC3N(C(c4cnc(Cl)cc4)c4ccccc4Cl)C(CC3)C2)c2ccccc2)CCO1\n",
      "-24.37    -24.37      8.83      0.26      c1c2c(ccc1OC)-c1c(sc(=NCC3CCN(C(C)=O)CC3)[nH]1)CCC2\n",
      "-25.28    -25.28     -1.84      0.18      c1(C(N)=O)ccc(C(N(Cc2cccs2)C)=O)cc1\n",
      "-24.27    -24.27     34.28      0.46      c1(F)cc(C(c2cc(C(=O)N(CC)CC)[nH]c2)=O)cc(F)c1\n",
      "-27.77    -27.77     44.67      0.57      N1Cc2c(-c3ccc(C)cc3)cccc2C1CC=C\n",
      "-31.68    -31.68    -17.89      0.11      c1cnc(-c2cc3ncn(C4(C)CCN(C(C5CC5)=O)CC4)c3cn2)cc1\n",
      "-22.01    -22.01     20.28      0.33      n1ccncc1N1CCN(C(c2cccc(OC)c2)=O)CC1\n",
      "Glide LigPrep Docking   raw_Glide LigPrep Docking\n",
      "0.23889151215553284   -6.792210102081299   \n",
      "0.20994886755943298   -6.61870002746582   \n",
      "0.022049779072403908   -4.047410011291504   \n",
      "0.05043281242251396   -4.940450191497803   \n",
      "0.25940054655075073   -6.906529903411865   \n",
      "0.18311482667922974   -6.441349983215332   \n",
      "0.45742636919021606   -7.822070121765137   \n",
      "0.5659542679786682   -8.276590347290039   \n",
      "0.10779209434986115   -5.79709005355835   \n",
      "0.3304086923599243   -7.263780117034912   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for element in data:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse the Results\n",
    "In order to analyze the run in a more intuitive way, we can use `tensorboard`:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "cd <your_path>/REINVENT_RL_demo\n",
    "\n",
    "# make sure, you have activated the proper environment\n",
    "conda activate reinvent.v3.0\n",
    "\n",
    "# start tensorboard\n",
    "tensorboard --logdir progress.log\n",
    "```\n",
    "\n",
    "Then copy the link provided to a browser window, e.g. \"http://workstation.url.com:6006/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results folder will hold four different files: the agent (pickled), the input JSON (just for reference purposes), the memory (highest scoring compounds in `CSV` format) and the scaffold memory (in `CSV` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",smiles,score,likelihood\r\n",
      "19,C(=NNC(N)=S)c1cc(OC2CCCC2)c(OC)cc1,0.6942421,-22.620014\r\n",
      "7,N1Cc2c(-c3ccc(C)cc3)cccc2C1CC=C,0.56595427,-27.769112\r\n",
      "28,c1c(Cn2c(=O)[nH]c3c(C)nc(C)n32)cccc1,0.5590625,-22.66359\r\n",
      "16,c1cc(Cn2c(CCCCN)cnc2)cc(Cl)c1,0.51199514,-27.736107\r\n",
      "3,C(C(N)=O)C(=O)N1CCN(c2ccc3c(c2)CN(C(=O)C)CC3)C=C1,0.4736048,-41.357193\r\n",
      "6,c1(F)cc(C(c2cc(C(=O)N(CC)CC)[nH]c2)=O)cc(F)c1,0.45742637,-24.27091\r\n",
      "18,c1(C2=NN(C(=O)C)C(c3ccccc3)C2)ccc(OC)cc1,0.43780145,-17.408478\r\n",
      "15,O1CCN(Cc2ccc(NC(=O)CC(C)=O)cc2)CC1,0.39261344,-24.114302\r\n",
      "17,c1(C=C2C(=O)N(C)C(=Nc3ccccc3)S2)ccc(N(CC)CC)c(Cl)c1,0.3528337,-28.79707\r\n",
      "18,Clc1ccccc1-c1[nH]c2c(n1)C(=O)CCC2,0.3498513,-22.323753\r\n",
      "24,Fc1c(C(C)=O)c(F)c(C(=O)c2ccc(=N)[nH]c2)c(Cl)c1,0.33398008,-24.691898\r\n",
      "9,n1ccncc1N1CCN(C(c2cccc(OC)c2)=O)CC1,0.3304087,-22.013836\r\n",
      "26,N(CC(=O)c1c(C(=O)c2ccccc2)ccc(C)c1)c1cc(Cc2ccccc2)ccc1,0.31439623,-43.123184\r\n",
      "23,O=S1(=O)CCC(n2c(=O)c3sc(-c4cccnc4)cc3[nH]c2=O)C1,0.29765692,-25.620085\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 {output_dir}/results/memory.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
