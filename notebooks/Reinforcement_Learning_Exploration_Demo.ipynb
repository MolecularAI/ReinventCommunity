{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.0`: reinforcement learning exploration demo\n",
    "This illustrates a use case where we aim to achieve an exploration behavior by generating as many as possible diverse solutions by using a predictive model as the main component.\n",
    "\n",
    "NOTE: The generated solutions might not be entirely reliable since they could be outside of the applicability domain of the predictive model. Predictive models could score highly compounds that are outside of the applicability domain but this score would be likely inaccurate. This mode would be more reliable if we aslo include `matching_substructure` component with a list of desired core structural patterns/scaffolds. Alternatively this mode can be quite successful in combination with docking or pharmacophore similarity. Such examples will be provided with the next releases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the paths\n",
    "_Please update the following code block such that it reflects your system's installation and execute it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"~/Desktop/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"~/miniconda3/envs/reinvent.v3.0\")\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_RL_Exploration_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the configuration \n",
    "In the cells below we will build a nested dictionary object that will be eventually converted to JSON file which in turn will be consumed by `REINVENT`. \n",
    "You can find this file in your `output_dir` location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Declare the run type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"reinforcement_learning\"   # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"scoring\" and \"create_model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Sort out the logging details\n",
    "This includes `result_folder` path where the results will be produced.\n",
    "\n",
    "Also: `REINVENT` can send custom log messages to a remote location. We have retained this capability in the code. if the `recipient` value differs from `\"local\"` `REINVENT` will attempt to POST the data to the specified `recipient`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://0.0.0.1\",          # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                # either to local logging or use a remote REST-interface\n",
    "    \"logging_frequency\": 10,             # log every x-th steps\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # load this folder in tensorboard\n",
    "    \"result_folder\": os.path.join(output_dir, \"results\"),     # will hold the compounds (SMILES) and summaries\n",
    "    \"job_name\": \"Reinforcement learning demo\",                # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                     # only relevant if \"recipient\" is set to a specific REST endpoint\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `\"parameters\"` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Set Diversity Filter\n",
    "During each step of Reinforcement Learning the compounds scored above `minscore` threshold are kept in memory. The scored smiles are written out to a file in the results folder `scaffold_memory.csv`. In the example here we are not using any filter by setting it to `\"IdenticalMurckoScaffold\"`. This will help to explore the chemical space since using the diversity filters will stimulate generation of more diverse solutions. The maximum average value of the scoring fuinction will be lower in exploration mode because the Agent is encouraged to search for diverse scaffolds rather than to only optimize the ones that are being found so far. The number of generated compounds should be higher in comparison to the exploitation scenario since the diversity is encouraged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"diversity_filter\"\n",
    "configuration[\"parameters\"][\"diversity_filter\"] =  {\n",
    "    \"name\": \"IdenticalMurckoScaffold\",     # other options are: \"IdenticalTopologicalScaffold\", \n",
    "                                           # \"IdenticalMurckoScaffold\" and \"ScaffoldSimilarity\"\n",
    "                                           # -> use \"NoFilter\" to disable this feature\n",
    "    \"nbmax\": 25,                           # the bin size; penalization will start once this is exceeded\n",
    "    \"minscore\": 0.4,                       # the minimum total score to be considered for binning\n",
    "    \"minsimilarity\": 0.4                   # the minimum similarity to be placed into the same bin\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Set Inception\n",
    "* `smiles` provide here a list of smiles to be incepted \n",
    "* `memory_size` the number of smiles allowed in the inception memory\n",
    "* `sample_size` the number of smiles that can be sampled at each reinforcement learning step from inception memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the inception (we do not use it in this example, so \"smiles\" is an empty list)\n",
    "configuration[\"parameters\"][\"inception\"] = {\n",
    "    \"smiles\": [],                          # fill in a list of SMILES here that can be used (or leave empty)\n",
    "    \"memory_size\": 100,                    # sets how many molecules are to be remembered\n",
    "    \"sample_size\": 10                      # how many are to be sampled each epoch from the memory\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Set the general Reinforcement Learning parameters\n",
    "* `n_steps` is the amount of Reinforcement Learning steps to perform. Best start with 1000 steps and see if thats enough.\n",
    "* `agent` is the generative model that undergoes transformation during the Reinforcement Learning run.\n",
    "\n",
    "We reccomend keeping the other parameters to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"reinforcement_learning\"] = {\n",
    "    \"prior\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"agent\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"n_steps\": 1000,                       # the number of epochs (steps) to be performed; often 1000\n",
    "    \"sigma\": 128,                          # used to calculate the \"augmented likelihood\", see publication\n",
    "    \"learning_rate\": 0.0001,               # sets how strongly the agent is influenced by each epoch\n",
    "    \"batch_size\": 128,                     # specifies how many molecules are generated per epoch\n",
    "    \"reset\": 0,                            # if not '0', the reset the agent if threshold reached to get\n",
    "                                           # more diverse solutions\n",
    "    \"reset_score_cutoff\": 0.5,             # if resetting is enabled, this is the threshold\n",
    "    \"margin_threshold\": 50                 # specify the (positive) margin between agent and prior\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Define the scoring function\n",
    "We will use a `custom_product` type. The component types included are:\n",
    "* `predictive_property` which is the target activity to _Aurora_ kinase represented by the predictive `regression` model. Note that we set the weight of this component to be the highest.\n",
    "* `qed_score` is the implementation of QED in RDKit. It biases the egenration of  molecules towars more \"drug-like\" space. Depending on the study case can have beneficial or detrimental effect.\n",
    "* `custom_alerts` the `\"smiles\"` field  also can work with SMILES or SMARTS\n",
    "\n",
    "Note: The model used in this example is a regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_product\",              # this is our default one (alternative: \"custom_sum\")\n",
    "    \"parallel\": False,                     # sets whether components are to be executed\n",
    "                                           # in parallel; note, that python uses \"False\" / \"True\"\n",
    "                                           # but the JSON \"false\" / \"true\"\n",
    "\n",
    "    # the \"parameters\" list holds the individual components\n",
    "    \"parameters\": [\n",
    "\n",
    "    # add component: an activity model\n",
    "    {\n",
    "        \"component_type\": \"predictive_property\", # this is a scikit-learn model, returning\n",
    "                                                 # activity values\n",
    "        \"name\": \"Aurora kinase\",                 # arbitrary name for the component\n",
    "        \"weight\": 6,                            # the weight (\"importance\") of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"model_path\": os.path.join(ipynb_path, \"models/Aurora_model.pkl\"),   # absolute model path\n",
    "            \"transformation\": {\n",
    "                \"transformation_type\": \"sigmoid\",  # see description above\n",
    "                \"high\": 9,                         # parameter for sigmoid transformation\n",
    "                \"low\": 4,                          # parameter for sigmoid transformation\n",
    "                \"k\": 0.25,                         # parameter for sigmoid transformation\n",
    "            },\n",
    "            \"scikit\": \"regression\",                # model can be \"regression\" or \"classification\"\n",
    "            \"descriptor_type\": \"ecfp_counts\",      # sets the input descriptor for this model\n",
    "            \"size\": 2048,                          # parameter of descriptor type\n",
    "            \"radius\": 3,                           # parameter of descriptor type\n",
    "            \"use_counts\": True,                    # parameter of descriptor type\n",
    "            \"use_features\": True                   # parameter of descriptor type\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: QED\n",
    "    {\n",
    "        \"component_type\": \"qed_score\", # this is the QED score as implemented in RDKit\n",
    "        \"name\": \"QED\",        # arbitrary name for the component\n",
    "        \"weight\": 2           # the weight (\"importance\") of the component (default: 1)                      \n",
    "    },\n",
    "\n",
    "    # add component: enforce to NOT match a given substructure\n",
    "    {\n",
    "        \"component_type\": \"custom_alerts\",\n",
    "        \"name\": \"Custom alerts\",               # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [                            # specify the substructures (as list) to penalize\n",
    "                \"[*;r8]\",\n",
    "                \"[*;r9]\",\n",
    "                \"[*;r10]\",\n",
    "                \"[*;r11]\",\n",
    "                \"[*;r12]\",\n",
    "                \"[*;r13]\",\n",
    "                \"[*;r14]\",\n",
    "                \"[*;r15]\",\n",
    "                \"[*;r16]\",\n",
    "                \"[*;r17]\",\n",
    "                \"[#8][#8]\",\n",
    "                \"[#6;+]\",\n",
    "                \"[#16][#16]\",\n",
    "                \"[#7;!n][S;!$(S(=O)=O)]\",\n",
    "                \"[#7;!n][#7;!n]\",\n",
    "                \"C#C\",\n",
    "                \"C(=[O,S])[O,S]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#7;!n]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#16;!s][C;!$(C(=[O,N])[N,O])][#16;!s]\"\n",
    "            ]\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:  Getting the selectivity score component to reach satisfactory levels is non-trivial and might take considerably higher number of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write out the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully filled the dictionary and will write it out as a `JSON` file in the output directory. Please have a look at the file before proceeding in order to see how the paths have been inserted where required and the `dict` -> `JSON` translations (e.g. `True` to `true`) have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"RL_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. Note, that depending on the number of epochs (steps) and the execution time of the scoring function components, this might take a while. \n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.0\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)\n",
    "\n",
    "# prepare the output to be parsed\n",
    "list_epochs = re.findall(r'INFO.*?local', captured_err_stream.stdout, re.DOTALL)\n",
    "data = [epoch for idx, epoch in enumerate(list_epochs) if idx in [1, 75, 124]]\n",
    "data = [\"\\n\".join(element.splitlines()[:-1]) for element in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the print-out of the first, one from the middle and the last epoch, respectively. Note, that the fraction of valid `SMILES` is high right from the start (because we use a pre-trained prior). You can see the partial scores for each component for the first couple of compounds, but the most important information is the average score. You can clearly see how it increases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     \n",
      " Step 0   Fraction valid SMILES: 100.0   Score: 0.2735   Time elapsed: 0   Time left: 0.0\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-22.95    -22.95     45.39      0.53      c1cc(CN(C)C(CN2CC(Cn3nc(C)cc3C)OCC2)=O)ccc1\n",
      "-27.15    -27.15    -27.15      0.00      O(C1CC(C)(C)CCC1)C1OC(CN)C(O)C(O)C1N\n",
      "-39.30    -39.30    -39.30      0.00      COc1c(C(N2CCC(=Cc3ccc(C(CCc4ccccc4OC)C)cc3)CC2)=O)ccc(C(=O)O)c1\n",
      "-24.93    -24.93     37.07      0.48      C(C)N(CCCC)c1nc(C)nc2c(-c3ccc(Cl)cc3)n(C)nc21\n",
      "-31.26    -31.26     31.66      0.49      N(C)(C)C(=O)C1CN(c2c(C3CN(C(C)C)CCC3)nccn2)CCC1\n",
      "-25.50    -25.50     25.75      0.40      C1CCC(C(=O)NCc2c(Cl)cc(F)cc2)(NC(=O)Nc2ccccc2OC)C1\n",
      "-27.32    -27.32     35.94      0.49      c1(NC(c2ccoc2C)=S)c(OS(c2ccccc2)(=O)=O)cccc1\n",
      "-23.88    -23.88     19.66      0.34      c1ccc(-c2sc(SCCCC#N)c(C#N)c2-c2ccc(Cl)cc2)cc1\n",
      "-21.01    -21.01    -21.01      0.00      c1cc(OCC(=O)N2CCC(C(=O)OCC)CC2)c(Cl)cc1Cl\n",
      "-21.03    -21.03    -21.03      0.00      C1COCCN1c1nc(-c2c[nH]c(=N)nc2)c2c(n1)N(C1(C)CCN(C(OC)=O)C1)CC2\n",
      "Aurora kinase   QED   Custom alerts   raw_Aurora kinase\n",
      "0.46805867552757263   0.7927606701850891   1.0   6.388873100280762   \n",
      "0.33447200059890747   0.5674968957901001   0.0   5.902386665344238   \n",
      "0.37565889954566956   0.35547494888305664   0.0   6.058743476867676   \n",
      "0.44020986557006836   0.6454669237136841   1.0   6.291268825531006   \n",
      "0.41342321038246155   0.8260467648506165   1.0   6.196139812469482   \n",
      "0.3397487998008728   0.654839813709259   1.0   5.9228973388671875   \n",
      "0.4811900854110718   0.5353596210479736   1.0   6.434616565704346   \n",
      "0.3424123227596283   0.33356210589408875   1.0   5.933191299438477   \n",
      "0.35343116521835327   0.757229745388031   0.0   5.975379943847656   \n",
      "0.49463173747062683   0.7176204323768616   0.0   6.481348037719727   \n",
      "\n",
      "INFO     \n",
      " Step 72   Fraction valid SMILES: 99.2   Score: 0.3310   Time elapsed: 52   Time left: 661.0\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-35.92    -34.98    -34.98      0.00      c1c(Br)cc(COc2ccc(OCCCC(=O)O)cc2)c(N2CCCC2=O)c1\n",
      "-17.57    -18.54     47.47      0.37      c1c([N+](=O)[O-])ccc(N2CCN(C(=O)C)CC2)c1\n",
      "-23.47    -24.65     41.77      0.37      c1c(NC(c2c(NC)cccc2)=O)c2ccccc2cc1\n",
      "-26.72    -27.13     44.00      0.40      C1CCN(c2c3[nH][nH]c(=O)c3c[nH]2)C1\n",
      "-25.01    -25.94     55.38      0.46      C1CC(N(c2ccc(C#N)c(Cl)c2)Cc2ccc(F)cc2F)CCN1C(C)C\n",
      "-31.73    -32.17     35.06      0.38      S(c1ccc2n(nc(-c3ccccc3)n2)c1)(=O)(N1CCCC(C(=O)N)C1)=O\n",
      "-21.64    -23.15     46.05      0.39      c1(-c2onc(C)n2)cc(S(=O)(=O)Nc2cc(C)ccc2)c(C)cc1\n",
      "-21.41    -21.80     31.20      0.30      c12ccc(C=CC(=NO)O)cc1OCCN2\n",
      "-19.53    -20.42     57.42      0.44      c1(S(N2CCN(C(c3cccnc3)=O)CC2)(=O)=O)ccc(Cl)cc1\n",
      "-19.30    -18.96     35.83      0.31      c1c(OC)ccc(OC)c1C(=NO)O\n",
      "Aurora kinase   QED   Custom alerts   raw_Aurora kinase\n",
      "0.36574676632881165   0.576003909111023   0.0   6.021835803985596   \n",
      "0.31866031885147095   0.584342896938324   1.0   5.83992862701416   \n",
      "0.29503971338272095   0.7547313570976257   1.0   5.743431568145752   \n",
      "0.34424901008605957   0.6247804760932922   1.0   5.940267562866211   \n",
      "0.4016823172569275   0.6719231009483337   1.0   6.15390157699585   \n",
      "0.3035842180252075   0.7273023128509521   1.0   5.778820991516113   \n",
      "0.3077497184276581   0.7838971614837646   1.0   5.795868873596191   \n",
      "0.29453837871551514   0.3075702488422394   1.0   5.741336822509766   \n",
      "0.3528728187084198   0.8322867751121521   1.0   5.973257064819336   \n",
      "0.30010515451431274   0.33228302001953125   1.0   5.764481544494629   \n",
      "\n",
      "INFO     \n",
      " Step 121   Fraction valid SMILES: 94.5   Score: 0.3459   Time elapsed: 89   Time left: 641.2\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-24.46    -26.09     53.30      0.45      C(c1cnccc1)n1c(C)cc2c1CCC(C)(C)C2\n",
      "-42.59    -42.31     22.84      0.37      c1n(C2C=CCC(c3cc4c(cccc4)cc3)O2)nnc1Cn1nnc(-c2cnccc2)n1\n",
      "-26.65    -27.87     40.46      0.38      c1c(-c2cc3c(cc2)n(C)c(C)n3)cc(Cl)c(O)c1\n",
      "-22.91    -24.84     59.60      0.47      C1CN(c2sc(-n3cccc3)nn2)CC(C(NCc2occc2)=O)C1\n",
      "-23.40    -25.59     47.76      0.41      c1(C)ccc(C(=O)Nc2cccc(CN3C(C)CCC3)c2)cc1\n",
      "-29.08    -30.65     42.11      0.41      c1(-c2[nH]c3ccc(NS(=O)(=O)c4ccc(N)cc4)cc3n2)ccoc1\n",
      "-21.42    -21.80     48.41      0.39      c1cccc(CS(=O)(Cc2oc(C(=O)NCc3ccc(F)cc3)cc2)=O)c1\n",
      "-23.26    -25.62     44.96      0.40      c1ncc(-c2nc(CN(C)Cc3nc(C)ccc3)co2)cc1\n",
      "-25.03    -27.07     58.25      0.48      c1ccc(CN=c2[nH]cnc3occc23)c(F)c1\n",
      "-31.62    -33.69     51.68      0.48      C1N(C(C2CN(c3cc(N4CCOCC4)ncn3)CCC2)=O)C(C)C1\n",
      "Aurora kinase   QED   Custom alerts   raw_Aurora kinase\n",
      "0.367461621761322   0.7976943850517273   1.0   6.028250217437744   \n",
      "0.3592619001865387   0.387231707572937   1.0   5.997461318969727   \n",
      "0.30993330478668213   0.7293262481689453   1.0   5.804754257202148   \n",
      "0.4055878818035126   0.7590003609657288   1.0   6.167994499206543   \n",
      "0.31569916009902954   0.9163632988929749   1.0   5.828052997589111   \n",
      "0.38554397225379944   0.48695558309555054   1.0   6.095166206359863   \n",
      "0.3299487233161926   0.6735584139823914   1.0   5.884676933288574   \n",
      "0.3244624435901642   0.7235572934150696   1.0   5.863029956817627   \n",
      "0.4127177596092224   0.75094074010849   1.0   6.193612575531006   \n",
      "0.4012598693370819   0.8189800381660461   1.0   6.152374744415283   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for element in data:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse the results\n",
    "In order to analyze the run in a more intuitive way, we can use `tensorboard`:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "cd <your_path>/REINVENT_RL_demo\n",
    "\n",
    "# make sure, you have activated the proper environment\n",
    "conda activate reinvent.v3.0\n",
    "\n",
    "# start tensorboard\n",
    "tensorboard --logdir progress.log\n",
    "```\n",
    "\n",
    "Then copy the link provided to a browser window, e.g. \"http://workstation.url.com:6006/\". The following figures are exmaple plots - remember, that there is always some randomness involved. In `tensorboard` you can monitor the individual scoring function components. \n",
    "\n",
    "The score for predicted Aurora Kinase activity.\n",
    "\n",
    "![](img/explore_aurora_kinase.png)\n",
    "\n",
    "The average score over time.\n",
    "\n",
    "![](img/explore_avg_score.png)\n",
    "\n",
    "It might also be informative to look at the results from the prior (dark blue), the agent (blue) and the augmented likelihood (purple) over time.\n",
    "\n",
    "![](img/explore_nll_plot.png)\n",
    "\n",
    "And last but not least, there is a \"Images\" tab available that lets you browse through the compounds generated in an easy way. In the molecules, the substructure matches that were defined to be required are highlighted in red (if present). Also, the total scores are given per molecule.\n",
    "\n",
    "![](img/molecules.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results folder will hold four different files: the agent (pickled), the input JSON (just for reference purposes), the memory (highest scoring compounds in `CSV` format) and the scaffold memory (in `CSV` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",smiles,score,likelihood\r\n",
      "97,c1(N2CCNCCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.8443355,-44.236416\r\n",
      "33,c1(N2CC(C)(C)OCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.84024966,-45.86971\r\n",
      "76,c1(N2CC3(CCCN3)CCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.8363101,-49.455368\r\n",
      "54,N1(c2ncncc2-c2cnn(CC3OCCN(C)CC3)c2)CCCC1,0.835907,-39.872902\r\n",
      "17,c1(N2CC3(CNC3)CCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.83589107,-51.555267\r\n",
      "1,c1(N2CCCC(C)C2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.83450735,-41.503124\r\n",
      "67,c1(N2CCNCC2C)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.83384526,-45.48246\r\n",
      "82,c1(N2CCC23CCNC3)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.83354634,-50.136818\r\n",
      "64,c1(N2CC(C)(C)NCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.833404,-47.416767\r\n",
      "121,c1(N2CCCC(NC(=O)C)CC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.8331898,-53.02701\r\n",
      "45,c1(N2CC(F)C(NC(=O)C)CC2)ncncc1-c1cnn(CC2OCC2)c1,0.83252877,-50.888874\r\n",
      "58,c1(N2CC(C)(CO)CCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.8324435,-54.67186\r\n",
      "75,c1(N2CC(C)(CC)OCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.8324077,-51.618008\r\n",
      "64,c1(N2CCNCC2)ncncc1-c1cnn(CC2OCCN(C)CC2)c1,0.83203405,-41.90396\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 {output_dir}/results/memory.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
