{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.2`: transfer learning mode demo (teachers forcing)\n",
    "#### The *transfer learning* mode can be used for either\n",
    "    1. Initial training of the Agent - where a newly built agent is trained from scratch while iterating through sufficiently large datasets over many epochs \n",
    "    2. Focusing of pre-trained Agent - where an already pre-trained agent is introduced to a small dataset for a small number of epochs.\n",
    "In this notebook we are going to illustrate the first scenario. The provided dataset is processed by the workflow illustrated in the `Data Preparation` example. The required input is an empty model and the dataset with which this empty model is created.  \n",
    "The Prior can be used afterwards for *reinforcement learning*, *tranfer learning* or just *sampling*.\n",
    "\n",
    "## This is a rather slow process that depends on the number of epochs and dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"~/Desktop/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"~/miniconda3/envs/reinvent.v3.2\")\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_transfer_learning_initial_training_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the configuration\n",
    "`REINVENT` has an entry point that loads a specified `JSON` file on startup. `JSON` is a low-level data format that allows to specify a fairly large number of parameters in a cascading fashion very quickly. The parameters are structured into *blocks* which can in turn contain blocks or simple values, such as *True* or *False*, strings and numbers. In this tutorial, we will go through the different blocks step-by-step, explaining their purpose and potential values for given parameters. Note, that while we will write out the configuration as a `JSON` file in the end, in `python` we handle the same information as a simple `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"transfer_learning\",       # other run types: \"scoring\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"reinforcement_learning\" and\n",
    "                                           #                  \"create_model\"\n",
    "    \"model_type\": \"default\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://127.0.0.1\",          # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # where the run's output is stored\n",
    "    \"job_name\": \"Transfer Learning demo\", # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                       # only relevant if \"recipient\" is set to \"remote\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to specify a path to an agent (parameter `model_path`), which can be a prior or trained agent. For the purpose of this notebook, we will use a prior shipped with the `REINVENT 3.2` repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below will define the settings for `adaptive_lr_config` property of the configuration. These parameters are defining the behavior of the learning rate. Note that the mode is set to `\"adaptive\"`. We recommend adhering to the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_lr_config = {\n",
    "      \"mode\": \"adaptive\", # other modes: \"exponential\", \"adaptive\", \"constant\"\n",
    "      \"gamma\": 0.8,\n",
    "      \"step\": 1,\n",
    "      \"start\": 5E-4,  # initial learning rate\n",
    "      \"min\": 1E-5,\n",
    "      \"threshold\": 1E-4,\n",
    "      \"average_steps\": 4,\n",
    "      \"patience\": 8,        # patience is the lower bound of how frequently the learning rate should change\n",
    "      \"restart_value\": 1E-5,\n",
    "      \"sample_size\": 10000,  # this is relevant for stats and decision on how to update the learning rate\n",
    "      \"restart_times\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_SMILES_path = os.path.join(ipynb_path, \"data/chembl.filtered.smi\") \n",
    "input_model_path = os.path.join(ipynb_path, \"models/random.prior.new\")\n",
    "output_model_path = os.path.join(output_dir, \"chembl.prior\")\n",
    "# The final focused agent will be named \"chembl.prior\"\n",
    "# The intermediate steps will be named \"chembl.prior.1\", \"chembl.prior.2\", \"chembl.prior.3\" and etc.\n",
    "\n",
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {\n",
    "    \"input_model_path\": input_model_path,          # path to prior or empty model\n",
    "    \"output_model_path\": output_model_path,        # location to store the chembl prior\n",
    "    \"input_smiles_path\": input_SMILES_path,        # path to input smiles\n",
    "    \n",
    "    \"save_every_n_epochs\": 1,      # how often to save the Prior. Here its stored after each epoch\n",
    "    \"batch_size\": 128,             # batch size the input data\n",
    "    \"num_epochs\": 3,               # number of epochs to train Prior (set to 3 in this notebook for illustration).\n",
    "                                   # in reality, 20 epochs could result in a sufficiently good Prior\n",
    "                                   # NOTE: 20 epochs could take days to compute\n",
    "    \"standardize\": False,          # we assume all SMILES strings have been pre-processed\n",
    "    \"randomize\": True,             # this triggers data augmentation and will slow down the training a bit.\n",
    "    \"adaptive_lr_config\": adaptive_lr_config        # setting the learning rate behavior\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"transfer_learning_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. \n",
    "This training might take days with the suggested dataset and the number of epochs.\n",
    "Best execute for just a couple of epoch to optain a realistic estimate.\n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "In order to analyze the run in a more intuitive way, we can use `tensorboard`:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "cd <your_path>/REINVENT_transfer_learning_demo\n",
    "\n",
    "# make sure, you have activated the proper environment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# start tensorboard\n",
    "tensorboard --logdir progress.log\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
