{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.2`: reinforcement learning with tanimoto similarity\n",
    "\n",
    "\n",
    "This is a simple example of running `Reinvent` with only 1 score component.\n",
    "\n",
    "NOTE: There is a detailed reasoning for each code block provided in the `Reinforcement Learning Demo` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the paths\n",
    "_Please update the following code block such that it reflects your system's installation and execute it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"~/Desktop/Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"~/miniconda3/envs/reinvent.v3.2\")\n",
    "output_dir = os.path.expanduser(\"~/Desktop/REINVENT_RL_Tanimoto_Similarity_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the configuration \n",
    "In the cells below we will build a nested dictionary object that will be eventually converted to JSON file which in turn will be consumed by `REINVENT`. \n",
    "You can find this file in your `output_dir` location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Declare the run type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"reinforcement_learning\",  # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"scoring\" and \"create_model\"\n",
    "    \"model_type\": \"default\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Sort out the logging details\n",
    "This includes `result_folder` path where the results will be produced.\n",
    "\n",
    "Also: `REINVENT` can send custom log messages to a remote location. We have retained this capability in the code. if the `recipient` value differs from `\"local\"` `REINVENT` will attempt to POST the data to the specified `recipient`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://0.0.0.1\",          # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_frequency\": 10,               # log every x-th steps\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # load this folder in tensorboard\n",
    "    \"result_folder\": os.path.join(output_dir, \"results\"),         # will hold the compounds (SMILES) and summaries\n",
    "    \"job_name\": \"Reinforcement learning demo\",                # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                       # only relevant if \"recipient\" is set to a specific REST endpoint\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `parameters` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Set Diversity Filter\n",
    "During each step of Reinforcement Learning the compounds scored above `minscore` threshold are kept in memory. Those scored smiles are written out to a file in the results folder `scaffold_memory.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"diversity_filter\"\n",
    "configuration[\"parameters\"][\"diversity_filter\"] =  {\n",
    "    \"name\": \"IdenticalMurckoScaffold\",     # other options are: \"IdenticalTopologicalScaffold\", \n",
    "                                           #                    \"NoFilter\" and \"ScaffoldSimilarity\"\n",
    "                                           # -> use \"NoFilter\" to disable this feature\n",
    "    \"nbmax\": 25,                           # the bin size; penalization will start once this is exceeded\n",
    "    \"minscore\": 0.4,                       # the minimum total score to be considered for binning\n",
    "    \"minsimilarity\": 0.4                   # the minimum similarity to be placed into the same bin\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Set Inception\n",
    "* `smiles` provide here a list of smiles to be incepted \n",
    "* `memory_size` the number of smiles allowed in the inception memory\n",
    "* `sample_size` the number of smiles that can be sampled at each reinforcement learning step from inception memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the inception (we do not use it in this example, so \"smiles\" is an empty list)\n",
    "configuration[\"parameters\"][\"inception\"] = {\n",
    "    \"smiles\": [],                          # fill in a list of SMILES here that can be used (or leave empty)\n",
    "    \"memory_size\": 100,                    # sets how many molecules are to be remembered\n",
    "    \"sample_size\": 10                      # how many are to be sampled each epoch from the memory\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Set the general Reinforcement Learning parameters\n",
    "* `n_steps` is the amount of Reinforcement Learning steps to perform. Best start with 1000 steps and see if thats enough.\n",
    "* `agent` is the generative model that undergoes transformation during the Reinforcement Learning run.\n",
    "\n",
    "We reccomend keeping the other parameters to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"reinforcement_learning\"] = {\n",
    "    \"prior\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"agent\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"n_steps\": 125,                        # the number of epochs (steps) to be performed; often 1000\n",
    "    \"sigma\": 128,                          # used to calculate the \"augmented likelihood\", see publication\n",
    "    \"learning_rate\": 0.0001,               # sets how strongly the agent is influenced by each epoch\n",
    "    \"batch_size\": 128,                     # specifies how many molecules are generated per epoch\n",
    "    \"margin_threshold\": 50                 # specify the (positive) margin between agent and prior\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Define the scoring function\n",
    "We will use only a `tanimoto_smiliarity` component with only one SMILES string:\n",
    "\n",
    "`\"O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\"`\n",
    "\n",
    "However, using multiple smiles strings is also acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_product\",                  # this is our default one (alternative: \"custom_sum\")\n",
    "    \"parallel\": False,                         # sets whether components are to be executed\n",
    "                                               # in parallel; note, that python uses \"False\" / \"True\"\n",
    "                                               # but the JSON \"false\" / \"true\"\n",
    "\n",
    "    # the \"parameters\" list holds the individual components\n",
    "    \"parameters\": [\n",
    "\n",
    "    # add component: use \n",
    "    {\n",
    "        \"component_type\": \"tanimoto_similarity\", \n",
    "        \"name\": \"Tanimoto similarity\",         # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [\"O=S(=O)(c3ccc(n1nc(cc1c2ccc(cc2)C)C(F)(F)F)cc3)N\"], # a list of SMILES can be provided\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write out the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully filled the dictionary and will write it out as a `JSON` file in the output directory. Please have a look at the file before proceeding in order to see how the paths have been inserted where required and the `dict` -> `JSON` translations (e.g. `True` to `true`) have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"RL_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. Note, that depending on the number of epochs (steps) and the execution time of the scoring function components, this might take a while. As we have only specified a low number of epochs (125) and all components should be fairly quick, this should not take too long in our case though.\n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)\n",
    "\n",
    "# prepare the output to be parsed\n",
    "list_epochs = re.findall(r'INFO.*?local', captured_err_stream.stdout, re.DOTALL)\n",
    "data = [epoch for idx, epoch in enumerate(list_epochs) if idx in [1, 75, 124]]\n",
    "data = [\"\\n\".join(element.splitlines()[:-1]) for element in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated a total of 125 epochs, let us quickly investigate how the agent fared. Below you see the print-out of the first, one from the middle and the last epoch, respectively. Note, that the fraction of valid `SMILES` is high right from the start (because we use a pre-trained prior). You can see the partial scores for each component for the first couple of compounds, but the most important information is the average score. You can clearly see how it increases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     \n",
      " Step 0   Fraction valid SMILES: 96.1   Score: 0.1925   Time elapsed: 0   Time left: 0.0\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-24.06    -24.06     24.81      0.38      c1cc(Br)ccc1-n1nccc1-c1ccc(O)cc1\n",
      "-34.76    -34.76     -6.81      0.22      O(c1c(-c2cncnc2N2CCOc3c2ccc(S(=O)(=O)N=c2[nH]ccs2)c3)ccc(CC)c1)C\n",
      "-21.95    -21.95    -17.88      0.03      [N-]=[N+]=NC1C(O)C(O)C(O)C(O)C1CO\n",
      "-24.64    -24.64    -16.49      0.06      C1CCC(C(=O)N)(NO)CC1\n",
      "-25.13    -25.13    -11.71      0.10      S(c1[nH]nc(C)n1)CC(NC(=O)COC)=O\n",
      "-43.96    -43.96    -22.52      0.17      C(C(=O)NC1CCc2c(cc(F)cc2)N(Cc2cccc(NC(=O)NCC)c2)C1=O)N(CCOC)C(=O)N(C)C\n",
      "-37.40    -37.40     -7.50      0.23      c1cc(COc2c(C(NC3CC(C)(C)NC(C)(C)C3)=O)cc(-c3ccc(CC)cc3)cn2)cnc1\n",
      "-36.07    -36.07    -19.97      0.13      C1CN(C(=O)C2CC(OC)CN2C(O)C(C)=O)CCC1c1c2c(cc(F)cc2)on1\n",
      "-29.90    -29.90      0.17      0.23      c12c(c(OCc3ccccc3)cc(OC(=O)c3ccccc3)c1)[nH]c(=O)o2\n",
      "-27.57    -27.57     -7.66      0.16      c1ccncc1Cn1c(=O)[nH]c(-c2cnccn2)c1O\n",
      "Tanimoto similarity\n",
      "0.38181817531585693   \n",
      "0.2183908075094223   \n",
      "0.0317460335791111   \n",
      "0.06363636255264282   \n",
      "0.10483870655298233   \n",
      "0.16753926873207092   \n",
      "0.23353293538093567   \n",
      "0.12574850022792816   \n",
      "0.23489932715892792   \n",
      "0.15555556118488312   \n",
      "\n",
      "INFO     \n",
      " Step 72   Fraction valid SMILES: 99.2   Score: 0.2434   Time elapsed: 26   Time left: 18.9\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-30.17    -33.48     19.55      0.30      c1(C(N)=O)cc(-c2ccc(CO)cc2)nc2c1cc(-c1cc(F)ccc1)cc2\n",
      "-19.12    -21.77     26.15      0.27      c1cccc(-c2cc(-c3ccccc3)nc(OCC=C)n2)c1\n",
      "-33.14    -31.51     -4.42      0.15      C(CCCC)c1c(OCCCCOCCCOc2c(CCCCCC)ccc(O)c2)cccc1\n",
      "-24.29    -24.17     22.14      0.26      c1(OC)cccc(Cn2c3c(c(C)n2)cccc3)c1\n",
      "-24.47    -22.68      6.76      0.17      c1(C2(C(OCC(NC)=O)=O)CCOCC2)ccc(Cl)cc1\n",
      "-19.80    -19.73     25.48      0.25      c1ccc2c(c1)C(=O)N(CNc1ccc(C)c(C)c1)C2=O\n",
      "-38.81    -39.25      0.19      0.22      c1cc(C(c2ccccc2)C(=O)N=Nc2c(O)[nH]c3cccc(N4CCOC4=O)c23)ccc1\n",
      "-20.21    -20.90     20.64      0.23      c1c(C(Nc2ccc(OC)cc2)=O)c(N)cc(Cl)c1\n",
      "-21.80    -21.55     20.95      0.24      C(CN(CCCl)c1ccc(NC(=O)Nc2ccc(Cl)cc2)cc1)Cl\n",
      "-26.34    -27.23     20.08      0.27      c1(C)cc(C)c(-n2c3c(c(C)n2)c(C(NCc2ccc(OC(C)C)cc2)=O)cc(C)n3)c(C)c1\n",
      "Tanimoto similarity\n",
      "0.2978723347187042   \n",
      "0.26923078298568726   \n",
      "0.15217390656471252   \n",
      "0.2601625919342041   \n",
      "0.1654135286808014   \n",
      "0.2539682686328888   \n",
      "0.2215568870306015   \n",
      "0.23333333432674408   \n",
      "0.23880596458911896   \n",
      "0.26582279801368713   \n",
      "\n",
      "INFO     \n",
      " Step 121   Fraction valid SMILES: 98.4   Score: 0.2836   Time elapsed: 44   Time left: 1.4\n",
      "  Agent     Prior     Target     Score     SMILES\n",
      "-25.11    -32.30     42.09      0.42      COc1ccccc1-c1n(-c2cc(-c3ccc(F)cc3)ccc2)nc(C(F)(F)F)c1\n",
      "-31.17    -29.85      8.02      0.21      c1(OC)nn2c(cc1)nnc2CNS(=O)(=O)c1c(C)cc(C)c(C)c1\n",
      "-25.33    -25.49     20.44      0.26      c1cc(C=Nc2c(C(=O)O)cccc2)ccc1C(C)CC\n",
      "-33.92    -37.48     -2.05      0.20      c12[nH]c(-c3cc(C)cc(C)c3)c(C(C)CNS(=O)(CC)=O)c1cc(C(C)(C(N1C(C)CN(C(=O)c3ccccc3)CC1)=O)C)cc2\n",
      "-33.21    -34.44     -9.52      0.14      CC(CC(N)C(NN(C)c1ccc(C(NC(CC(C)C)C(O)=O)=O)cc1)=O)C\n",
      "-23.74    -26.51     17.06      0.24      c1c(C(c2ccc(C)o2)=O)c(-c2cc(OC)c(O)cc2)n(CCN(C)C)c1O\n",
      "-17.32    -20.59     43.73      0.36      c1c(-c2occ(CNCc3ccc(C)cc3)n2)cccc1\n",
      "-18.27    -25.33     37.83      0.35      c1ccc(-c2cc(-c3ccc(C(F)(F)F)cc3)nc(C(=O)O)c2)cc1\n",
      "-20.03    -20.97     15.21      0.20      c1cccc(OC)c1-c1oc(SCC(=O)O)nn1\n",
      "-22.20    -23.50     21.28      0.25      C(NCc1ccc2c(c1)OCO2)(c1ccc(S(Nc2ccc(OCC)cc2)(=O)=O)cc1)=O\n",
      "Tanimoto similarity\n",
      "0.41791045665740967   \n",
      "0.21276596188545227   \n",
      "0.25806450843811035   \n",
      "0.19900497794151306   \n",
      "0.14000000059604645   \n",
      "0.24475523829460144   \n",
      "0.3613445460796356   \n",
      "0.35483869910240173   \n",
      "0.20325203239917755   \n",
      "0.2515723407268524   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for element in data:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse the results\n",
    "In order to analyze the run in a more intuitive way, we can use `tensorboard`:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "cd <your_path>/REINVENT_RL_demo\n",
    "\n",
    "# make sure, you have activated the proper environment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# start tensorboard\n",
    "tensorboard --logdir progress.log\n",
    "```\n",
    "\n",
    "Then copy the link provided to a browser window, e.g. \"http://workstation.url.com:6006/\". The following figures are exmaple plots - remember, that there is always some randomness involved. In `tensorboard` you can monitor the individual scoring function components. What you see is, that all of those depicted went up (and `Fraction_valid_SMILES` was high troughout). Not shown is the predictive model, which did not perform all that well, so you might want to consider a higher weight next time.\n",
    "\n",
    "![](img/individual_components.png)\n",
    "\n",
    "Also the total score increased over time.\n",
    "\n",
    "![](img/total_score.png)\n",
    "\n",
    "It might also be informative to look at the results from the prior (dark blue), the agent (blue) and the augmented likelihood (purple) over time.\n",
    "\n",
    "![](img/likelihood.png)\n",
    "\n",
    "And last but not least, there is a \"Images\" tab available that lets you browse through the compounds generated in an easy way. In the molecules, the substructure matches that were defined to be required are highlighted in red (if present). Also, the total scores are given per molecule.\n",
    "\n",
    "![](img/molecules.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results folder will hold four different files: the agent (pickled), the input JSON (just for reference purposes), the memory (highest scoring compounds in `CSV` format) and the scaffold memory (in `CSV` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",smiles,score,likelihood\r\n",
      "20,c1c(C(F)(F)F)nn(-c2ccc(S(=O)(=O)C)cc2)c1-c1ccc(C)cc1,0.84615386,-20.00452\r\n",
      "77,c1cc(-c2n(-c3ccc(S(=O)(N)=O)cc3)nc(C(F)(F)F)c2)ccc1S(=O)(=O)C,0.84210527,-18.852293\r\n",
      "114,c1cc(-c2cc(C(F)(F)F)nn2-c2ccc(S(=O)(=O)N)cc2)ccc1,0.82417583,-16.594893\r\n",
      "28,c1cc(-n2c(-c3ccc(S(=O)(N)=O)cc3)cc(C(F)(F)F)n2)ccc1C(F)(F)F,0.8229167,-23.325848\r\n",
      "114,c1c(F)ccc(-c2cc(C(F)(F)F)nn2-c2ccc(S(N)(=O)=O)cc2)c1,0.8064516,-17.753906\r\n",
      "83,Clc1ccc(-c2n(-c3ccc(S(=O)(N)=O)cc3)nc(C(F)(F)F)c2)cc1,0.8064516,-17.646894\r\n",
      "51,c1c(C)c(OC)cc(-c2n(-c3ccc(S(N)(=O)=O)cc3)nc(C(F)(F)F)c2)c1,0.78571427,-24.004723\r\n",
      "101,c1cc(-n2c(C(F)(F)F)cc(-c3ccc(C)cc3)n2)ccc1S(=O)(N)=O,0.76842105,-21.211304\r\n",
      "115,c1(Cl)cc(-c2n(-c3ccc(S(N)(=O)=O)cc3)nc(C(F)(F)F)c2)ccc1,0.7604167,-20.087582\r\n",
      "8,c1c(S(=O)(=O)N)ccc(-n2c(-c3ccc(OC(F)(F)F)cc3)cc(C(F)(F)F)n2)c1,0.7378641,-20.552412\r\n",
      "90,O=S(=O)(C)Nc1ccc(-c2cc(C(F)(F)F)nn2-c2ccc(C)cc2)cc1,0.7373737,-21.294903\r\n",
      "60,c1cc(C)ccc1-c1cc(C(F)(F)F)nn1-c1ccc(S(=O)(=O)N)c(COC(=O)C)c1,0.712963,-24.771164\r\n",
      "82,c1ccccc1-c1n(-c2ccc(S(=O)(=O)C)cc2)nc(C(F)(F)F)c1,0.7113402,-18.767412\r\n",
      "8,c1c(Br)ccc(-c2cc(C(F)(F)F)nn2-c2ccc(S(=O)(C)=O)cc2)c1,0.6969697,-19.866903\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 {output_dir}/results/memory.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
